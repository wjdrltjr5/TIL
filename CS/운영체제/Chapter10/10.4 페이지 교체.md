# 페이지 교체
다중 프로그래밍 정도를 더 올리면 메모리 과할당이 발생한다. 10개의 페이지 중 5개만을 사용하는 6개의 프로세스를 실행시키면 10개의 프레임은 남겨놓고도 높은 CPU활용률과 처리율을 얻을 수 있다. 그러나 특정 데이터 조합에 대해 이 프로세스들이 10페이지 모두를 사용해야 하는 상황이 발생할 수 있고 이러면 40프레임만이 존재하는 상황에서 60프레임을 필요로 하게 된다.

더욱이 시스템 메모리는 프로그램 페이지를 저장하는 용도로만 사용되는 것이 아니라 I/O를 위한 버퍼도 상당한 양의 메모리를 사용하고, 이는 메모리 할당 알고리즘의 부담을 증가시킨다.

얼마만큼의 메모리를 I/O 용도로 할당하고 얼마만큼의 메모리는 프로그램에 할당하는가 하는 것은 매우 중요한 문제이다. 어떤 시스템은 I/O 버퍼로 정해진 비율만큼의 메모리를 할당하고 어떤 시스템은 프로세스들과 I/O 서브시스템 양쪽이 전체 메모리를 대상으로 할당 경쟁을 벌이도록 하기도 한다.

메모리의 초과 할당은 다음과 같이 나타난다. 프로세스가 실행되는 동안 페이지 폴트가 발생한다 운영체제는 필요로 하는 페이지가 보조저장장치에 저장된 위치를 알아내지만 가용한 프레임 목록에 가용한 프레임이 없음을 발견한다.

즉 모든 메모리가 사용중이다. 이 시점에서 운영체제는 몇 가지 선택을 할 수 있다. 프로세스를 종료할 수 있다. 그러나 요구 페이징은 시스템의 활용률과 처리율을 올리기 위해 운영체제가 선택한 방법이다.

사용자가 그들의 프로세스가 페이징 시스템에서 실행되고 있음을 알게 해서는 안된다. 페이징은 논리적으로 투명해야 한다. 따라서 프로세스 종료는 가장 좋은 선택은 아니다.

대신 운영체제는 표준 스와핑을 사용하여 프로세스를 스왑아웃 하여 모든 프레임을 비우고 다중 프로그래밍 정도를 줄일 수 있다. 하지만 메모리와 스왑 공간 사이에 전체 프로세스를 복사하는 오버헤드로 인해 대부분의 운영체제에서는 표준 스와핑이 더는 사용되지 않는다.

대부분의 운영체제는 페이지 스와핑과 페이지 교체를 결합한다.

- 페이지 스와핑 : 페이지를 메모리와 디스크 사이에서 이동시키는 행위
- 페이지 교체 : 메모리내의 페이지 중 희생양을 선택하여 내보내는 행위

## 10.4.1 기본적인 페이지 교체
페이지 교체는 빈 프레임이 없다면 현재 사용되고 있지 않는 프레임을 찾아서 그것을 비워버린다. 그 프레임의 내용을 스왑공간에 쓰고 그 페이지가 메모리에 이제는 존재하지 않는다는 것을 나타내기 위해 페이지 테이블을 변화시킴으로써 프레임을 비어 있게 한다. 

이제 비워진 프레임을 페이지 폴트 발생시킨 프로세스에서 사용할 수 있게 된다.
1. 보조저장장치에서 필요한 페이지의 위치를 알아낸다.
2. 빈 페이지 프레임을 찾는다.
    - 비어 있는 프레임이 있다면 그것을 사용한다.
    - 비어 있는 프레임이 없다면 희생될 프레임을 선정하기 위하여 페이지 교체 알고리즘을 사용한다.
    - 희생될 페이지를 보조저장장치에 기록하고 관련 테이블을 수정한다.
3. 뺴앗은 프레임에 새 페이지를 읽어오고 테이블을 수정한다.
4. 페이지 폴트가 발생한 지점에서부터 프로세스를 계속한다.

빈 프레임이 없는 경우 디스크를 두번접근(비울때, 읽을때)해야 한다는 사실에 주의 이와 같은 상황에서는 페이지 폴트 처리시간이 2배 소요되며, 그에 따라 실질 접근 시간도 증가한다.

이러한 오버헤드는 변겨 ㅇ비트를 사용해서 감소시킬 수 있다. 각 페이지나 프레임은 그것과 관련된 변경 비트를 하드웨어에 가지게 된다.

변경 비트는 CPU가 페이지 내의 어떤 바이트라도 쓰게 되면 페이지가 변경되었음을 나타내기 위해 설정된다. 희생시킬 페이지가 선정되면 변경 비트를 확인한다. 변경 비트가 설정되어 있으면 페이지 내용이 원래 보조저장장치상의 내용과 달라졌음을 알 수 있다. (반대로 변경 비트가 설정되어있지 않으면 변경되지 않았음을 알 수 있다. 이러면 보조저장장치에 기록할 필요도 없다.)

페이지 교체는 요구 페이징의 기본이다 이를 통해 논리적 메모리와 물리 메모리간의 분리가 완성된다. 요구 페이징 시스템은 두 가지 중요한 문제를 해결해야 하는데, 프레임 할당 알고리즘과 페이지 교체 알고리즘이다. 

각 프로세스에 얼마나 많은 프레임을 할당해야 할지 결정해야 하고 페이지 교체가 필요한 경우 어떤 페이지를 교체해야 할지 결정해야 한다. (보조저장장치I/O가 비용이 많이 든다는 것을 생각하면 매우 중요하다.)

페이지 교체 알고리즘의 성능은 특정 메모리 참조 나열에 대해 알고리즘을 적용하여 페이지 폴트 발생 횟수를 계산하여 평가한다. 이러한 메모리 주소의 나열을 참조열이라 부른다.

## 10.4.2 FIFO페이지 교체
FIFO 교체 알고리즘은 어떤 페이지를 교체해야 할때, 메모리에 올라온지 가장 오래된 페이지를 내쫒는다.

FIFO 페이지 교체 알고리즘은 이해하기도 쉽고 프로그램 하기도 쉽다. 그러나 성능이 항상 좋지는 않다. FIFO 교체 알고리즘에서는 Belady의 모순이 발생한다.(페이지 프레임을 더 크게 줬는데 페이지 폴트가 더 많이 발생하는 현상)

## 10.4.3 최적 페이지 교체(Optimal Page Replacement)
Belady의 모순이 가져온 결과 중 하나는 최적 교체 정책에 대한 탐색이다. 최적 교체 정책이란 모든 알고리즘보다 낮은 페이지 폴트율을 보이며 Belady의 모순이 발생하지 않는 것이다.

`앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체하라`

이 알고리즘의 실제 구현은 어렵다. 이 방식은 프로세스가 앞으로 메모리를 어떻게 참조할 것인지를 미리 알아야 하기 때문이다. 따라서 최적 페이지 교체 알고리즘은 주로 비교 연구 목적을 위해 사용한다.

## 10.4.4 LRU 페이지 교체
최근의 과거를 가까운 미래의 근사치로 본다면 가장 오랜기간 동안 사용되지 않은 페이지를 교체할 수 있다. 이기법이 least-recently-used(LRU) 알고리즘이다.

LRU알고리즘은 페이지마다 마지막 사용 시간을 유지한다. 페이지 교체 시에 LRU는 가장 오랫동안 사용되지 않은 페이지를 선택한다. 이정책은 미래 대신 과거 시간에 대해 적용한 최적 교체 정책으로 생각할 수 있다.

LRU 정책은 페이지 교체 알고리즘으로 자주 사용되며 좋은 알고리즘으로 인정받고 있다. LRU구현 방법은 두가지가 있다. 
- 계수기 : 가장 간단한 방법으로 각 페이지 항목마다 사용 시간 필드를 넣고 CPU에 논리적인 시계나 계수기를 추가한다. 메모리가 접근될 때마다 시간은 증가한다.
    -  페이지에 대한 참조가 일어날 때마다 페이지의 사용 시간 필드에 시간 레지스터의 내용이 복사된다. 이렇게 각 페이지의 마지막 참조 시간을 유지할 수 있다 시간 값이 가장 작은 페이지가 교체된다.
    - 이 기법에서는 LRU 페이지를 찾기 위해 페이지 테이블을 탐색하여야 하며, 메모리 참조 때마다 메모리 쓰기 작업을 필요로 한다.

- 스택 : LFU 교체 정책의 다른 구현 방법은 페이지 번호의 스택을 유지하는 방법이다.
    - 페이지가 참조될 때마다 페이지 번호는 스택 중간에서 제거되어 스택 꼭대기에 놓이게 된다. 이런 방식으로 하면 스택의 꼭대기에는 항상 가증 최근에 사용된 페이지고 밑바닥은 가장 오랫동안 이용되지 않은 페이지다.
    - 스택의 중간에서 항목을 제거해야 할 필요가 있으므로 스택은 보통 doubly linked list로 구현한다.

최적 교체와 마찬가지로 LRU교체는 Belady의 모순 현상을 야기하지 않는다. 페이지 교체 알고리즘 중에는 Belady의 모순 현상을 나타내지 않는 것들이 있다. 이러한 알고리즘들을 스택 알고리즘이라고 부른다.

양쪽 LRU 구현 방법 모두 반드시 표준적인 TBL 레지스터 이상의 하드웨어 지원이 있어야 한다.

계수기 값과 스택을 갱신하는 일을 메모리 참조 때마다 수행되어야 한다. 이러한 작업을 소프트웨어로 하기 위해 인터럽트로 한다면 최소 10배 이상 메모리 참조 속도가 느려지고 결국 프로세스의 실행 속도 역시 저하된다. 이러한 오버헤드를 감당할 수 있는 시스템은 거의 없다.

## 10.4.5 LRU 근사 페이지 교체
LRU페이지 교체 지원을 충분히 할 수 있는 하드웨어는 많지 않다. 그러나 많은 시스템은 참조 비트의 형태로 어느 정도의 지원은 하고 있다.

페이지 참조가 있을 때마다 하드웨어가 그 페이지에 대한 참조 비트를 설정한다. 참조 비트는 페이지 테이블에 있는 각 항목과 대응된다.

처음에 모든 참조 비트는 운영체제에 의해 0으로 채워진다. 프로세스가 실행되면서 참조되는 페이지의 비트는 하드웨어가 1로 세팅한다. 얼마가 지나면 페이지 사용의 순서는 모르지만 어떤 페이지가 사용되었고 사용되지 않았는지를 알 수 있다. 이러한 부분적인 정보가 많은 LRU 근사 알고리즘의 기본이 된다.

### 10.4.5.1 부가적 참조 비트 알고리즘
일정한 간격마다 참조 비트들을 기록함으로써 추가적인 선후 관계 정보를 얻을 수 있다.

각 페이지에 대해 8비트의 참조 비트를 할당한다. 일정한 시간 간격마다, 타이머 인터럽트를 걸어서 운영체제가 참조 비트를 8비트 정보의 최상위 비트로 이동시키노 나머지 비트들은 하나씩 오른쪽으로 이동시킨다.

이 8비트 시프트 레지스터는 가장 최근 8구간 동안의 그 페이지의 사용 기록을 담고 있다. 만약 시프트 레지스터의 값이 00000000이라면 페이지를 8번의 구간동안 한 번도 사용하지 않았다는 뜻이고 구간마다 최소한 한 번 이상 사용된 페이지는 11111111 시프트 레지스터값을 가진다.

레지스터값이 11000100인 페이지는 01110111인 페이지보다 더 최근에 사용되었다. 이 8비트 값을 정수로 생각하면 가장 작은 수를 갖는 페이지가 LRU페이지가 되고 이를 교체할 수 있다. 

가장 작은 값을 갖는 페이지 모두를 교체할 수도 있고 그들 사이에서 FIFO방식으로 하나를 선택할 수도 있다.(사용하는 비트 수는 달라질 수 있다.)

### 10.4.5.2 2차 기회 알고리즘
2차 기회 알고리즘의 기본은 FIFO교체 알고리즘이다. 그러나 페이지가 선택될 때마다 참조 비트를 확인한다. 참조 비트가 0이면 페이지를 교체하고 1이면 다시 한번 기회를 주고 다음 FIFO 페이지로 넘어간다.

한 번 기회를 받게 되면 참조 비트는 해제되고 도착 시간이 현재 시간으로 재설정된다. 이에 따라 그 페이지는 다른 모든 페이지가 교체(or 재기회)될 떄까지 교체되지 않는다. 따라서 참조 비트그 계속 설정되어 있을 정도로 자주 사용되는 페이지는 전혀 교체되지 않을 것이다.

2차기회 알고리즘을 구현하는 하나의 방법은 순환 큐를 이용하는 것이다. 이 큐에는 포인터가 있어서 다음에 교체될 페이지를 가리킨다. 어떤 프레임을 빼앗아야 할 일이 생기면 포인터는 0값의 참조비트를 가진 페이지를 찾을때가지 큐를 뒤진다.

### 10.4.5.3 개선된 2차 기회 알고리즘
기존 2차 기회 알고리즘에 참조 비트와 변경 비트를 사용하면 더 개선할 수 있다. 두 개의 비트를 조합하여 사용하면 다음 네 가지의 등급이 가능하다.
- 0,0 최근에 사용되지도 변경되지도 않은 경우 -> 교체하기 가장 좋은 페이지
- 0,1 최근에 사용되지는 않았지만 변경은 된 경우 -> 이 페이지는 뺏어 오려면 디스크에 내용을 기록해야 하므로 교체에 적당하지 않다.
- 1,0 최근에 사용은 되었으나 변경은 되지 않은 경우 -> 이 페이지는 곧 다시 사용될 가능성이 높음
- 1,1 최근에 사용도 되었고 변경도 된경우 -> 곧 다시 사용될 것이며 뻇으면 디스크에 기록도 해야함

페이지 교체가 필요할때 각 페이지가 어떤 등급에 속하는 지를 확인하고 가장 낮은 등급을 가진 페이지를 교체한다. 이 알고리즘은 I/O 횟수를 줄이기 위해 변경된 페이지에 대해 우선순위를 준다는 것

## 10.4.6 계수 기반 페이지 교체
- LFU (least frequently used) 알고리즘 : 참조 횟수가 가장 작은 페이지를 교체하는 방법이다. 이러한 선택의 이유는 활발하게 사용되는 페이지는 큰 참조 횟수 값을 갖게 될 것이라는 점이다. 
    - 이 알고리즘은 어떤 프로세스가 그 초기 단계에서는 한 페이지를 집중적으로 많이 사용하지만 그 후로는 사용하지 않을때 판단이 빗나갈 수 있다.
    - 해결책은 참조 횟수를 일정 시간마다 오른쪽으로 시프트해서 지수적으로 그 영향역을 감소시키는 방법

- MFU(most frequently used) 알고리즘 : 가장 작은 참조 횟수를 가진 페이지가 가장 최근 참조된 것이고 앞으로 사용될 것이라는 판단에 근거한 것이다.

MFU나 LFU는 일반적으로 잘 쓰이지 않는다. 구현하는데 비용이 들고 최적 페이지 교체 정책을 제대로 근사하지 못하기 때문이다.

## 10.4.7 페이지-버퍼링 알고리즘
페이지 교체 알고리즘과병행하여 여러 가지 버퍼링 기법이 사용될 수 있다. 한 가지 기법은 시스템들이 가용 프레임 여러 개를 풀(pool)가지고 있다가 페이지 폴트가 발생하면 에전과 마찬가지로 교체될 페이지를 찾지만, 교체될 페이지의 내용을 디스크에 기록하기 전에 가용 프레임에 새로운 페이지를 먼저 읽어 들이는 방법이다.

이 방법은 교체될 페이지가 쓰이기를 기다리지 않고 프로세스가 가능한 한 빨리 시작할수 있도록 해준다. 이후에 교체될 페이지가 다 쓰이고 나면 그 프레임이 가용 프레임 풀에 추가도니다.

이 개념의 확장으로 변경된 페이지 리스트를 유지하는 방법이 있다. 페이징 장치가 아무런 일도 없게 되면 그때마다 변경된 페이지들을 차례로 보조저장장치에 쓴 후에, 페이지의 변경 비트를 0으로 되돌려 놓는다. 이렇게 하면 나중에 페이지가 실제로 교체될 때 변경되지 않은 상태여서 쓰기 작업이 불필요할 가능성이 높아진다.

다른 방법은 가용 프레임 풀을 유지하지만 그 풀 속 각 프레임의 원래 임자 페이지가 누구였었는지를 기억해 놓는 것이다. 풀 속의 프레임 내용은 그것을 보조저장장치에 썻다고하더라도 수정되지 않았을 확률이 있으므로 거기에 저장되어 있던 페이지는 프레임이 사용되기 전까지는 다시 사용될 수 있기 때문이다.

이 경우 I/O는 전혀 필요하지 않다 따라서 페이지 폴트가 일어날 때 찾는 페이지가 아직도 풀에 훼손되지 않은 채로 남아있는지 검사한후 만약 없으면 그때 페이지를 읽어 들인다.

## 10.4.8 응용과 페이지 교체
몇몇 경우에는 운영체제의 가상 메모리를 통해 데이터에 접근하는 응용이 운영체제가 전혀 버퍼링 기능을 제공하지 않는 경우에 비해 오히려 안 좋은 성능을 보일 때가 있다.

대표적으로 나름의 메모리 관리와 I/O 버퍼링을 수행하고 있는 데이터베이스이다. 이러한 응용들은 범용적인 알고리즘을 구현해야 하는 운영체제와 비교하여 자신의 메모리 저장장치 사용 방식을 더 잘 알고 있다. 또한 운영 체제가 I/O를 버퍼링 하고 응용프로그램도 버퍼링 한다면 I/O 에 대해 메모리를 두 배로 사용하게 된다.

DW는 자주 연속적인 대량의 읽기 작업 후에 계산과 쓰기 작업을 수행하게 된다. LRU알고리즘은 오래된 페이지들을 버리고 새로운 페이지들을 유지하려고 하는데, 응용은 새로운 페이지에 비해 오래된 페이지를 읽을 가능성이 더 높다. 이때는 MFU가 LRU보다 더 효율적일 수 있다.

이러한 문제들 때문에 몇몇 운영체제는 특별한 프로그램들에게는 보조저장장치 파티션을 파일 시스템 구조가 아닌 단순한 논리적인 블록들의 순차적인 배열로써 사용할 수 있게 해주는 기능을 가지고 있다.

raw disk라고 불리며 여기에 대한 I/O는 rawI/O라는 용어를 사용한다. 특정 응용들이 raw파티션을 이용해 자신만의 특수한 저장장치 서비스를 구현하는 것이 효율적인 데 비해 대부분의 응용들은 정상적인 파일 시스템서비스를 이용해 동작하는 것이 효율적이다.
