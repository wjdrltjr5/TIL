# 통계정보 2

## 전략적인 통계수집 정책의 중요성

지금까지 설명한 카디널리티와 비용 계산식의 세부적인 사항을 항상 기억할 필요는 없다. 다만 그 원리를 이해함으로써 통계정보 수집이 얼마나 중요한지 깨닫는 것은 매우 중요하다.

### CBO 능력을 최대한 끌어 올리는 핵심 요소

통계정보가 CBO에게 미치는 영향을 절대적이다. 옵티마이저가 그 능력을 최대한 발휘할 수 있도록 환경을 조성해 주어야 한다.

옵티마이저가 이상한 실행계획을 하는 경우 대부분은 통계정보 이상이다.

### DB 관리자의 핵심 역할은 통계정보 관리

DBA라고 하면 흔히 오브젝트 생성 관리, 백업 & 복구, 트러블 슈팅 등을 떠올리지만 CBO 환경에서 그 이상으로 중요한 역할은 통계정보 수집 정책을 세우고 그에 따라 통계정보를 안정적으로 운영 관리하는 데 있다.

문제없던 쿼리아 악성 SQL로 돌변했다면 테이블 통계정보에 이상없는지를 가장 먼저 확인하라

### 통계정보 수집 시 고려사항

통계정보를 수집할 때 고려해야 할 중요한 네 가지 요소는 다음과 같다.

-   시간 : 부하가 없는 시간대에 가능한 빠르게 수집을 완료해야 함.
-   샘플 크기 : 가능한 적은 양의 데이터를 읽어야 함
-   정확성 : 전수 검사할 떄의 통계치에 근접해야 함
-   안정성 : 데이터에 큰 변화가 없는데 매번 통계치가 바뀌지 않아야 함

가장 짧은 시간 내에 꼭 필요한 만큼만 데이터를 읽어 충분한 신뢰수준을 갖춘 안정적인 통계정보를 옵티마이저에게 제공하려면 치밀한 전략이 있어야 한다.

### 주기적으로 통계 수집하면서 안정적이어야 최적

통계정보의 중요성은 무엇보다 좋은 실행계획을 통해 쿼리 성능을 높이는 데 있다. 따라서 정확성이 무엇보다 중요하며,

특히 OLAP 처럼 비정형 쿼리들이 많은 시스템에선 시스템 성능을 결정짓는 가장 중요한 변수로 작용한다.

`통계정보를 주기적으로 수집하면서도 안정적으로 운영되는 시스템이야 말로 최적`

### 통계 수집 정책 수립은 필수

몇 가지 운영전략을 소개하면,

통계를 수집할 필요가 없는 오브젝트에 대해서는 Lock 옵션으로 통계정보를 고정할 수 있다.

그리고 통계정보에 영향을 받아선 안 되는 중요한 일부 핵심 프로그램에 대해선 옵티마이저 힌트를 적용해 실행계획을 고정시키는 것이 최선이다.

운영 DB에서 수집한 통계정보를 개발 DB에도 반영한 상태에서 개발을 진행해야 하며, 프로그램을 운영 서버에 배포하기 전 충분한 테스트를 거쳐야 한다.

운영 서버와 테스트 서버 간에는 오브젝트 통계뿐만 아니라 시스템 통계까지 일치시켜야 하며, 당연히 옵티마이저 관련 파라미터도 일치시켜야 한다.

테이블 정의서에 기록하든 별도 산출물을 이용하든 데이터베이스 설계 시 주요 태스크로 진행해야 하고, 이를 기준으로 스크립트를 작성해 시스템 오픈 전에 적정성 여부를 반드시 테스트 해야 한다.

모든걸 자동 기능에 의존한다면 시스템 운명을 오라클에 내맡기는 것과 다름 없다.

## DBMS_STATS

이제는 Analyze 명령어를 버리고 이제는 dbms_stats 패키지를 사용하는 것이 바람직하다.

dbms_stats가 더 정교하게 통계를 계산해 내기 때문이며, 특히 파티션 테이블/인덱스일 때는 반드시 dbms_stats를 사용해야 한다.

```
Analyze 문장이 deprecated 된것은 아니며 아래와 같은 정보 수집을 위해 여전히 필요하다.

- freelist 블록 정보 수집 : avg_space_freelist_blocks, num_freelist_blocks

- 체인이 발생한 로우 개수 확인 : chain_cnt
- list chained rows : 로우 체인 또는 마이그레이션이 발생한 로우 식별
- validate : 정합성이 깨진 데이터 블록이나 로우가 있는지 검증
```

#### dbms_stats.gather_table_stats 프로시저 인자 표

| 인자 이름          | 데이터 타입 | 설명                                                                         |
| ------------------ | ----------- | ---------------------------------------------------------------------------- |
| `ownname`          | VARCHAR2    | 스키마(소유자) 이름. NULL이면 현재 사용자.                                   |
| `tabname`          | VARCHAR2    | 테이블 이름.                                                                 |
| `partname`         | VARCHAR2    | 파티션 이름. 특정 파티션만 통계 수집 시 사용.                                |
| `estimate_percent` | NUMBER      | 샘플링 비율 (예: `DBMS_STATS.AUTO_SAMPLE_SIZE` 권장).                        |
| `block_sample`     | BOOLEAN     | 블록 샘플링 여부. TRUE이면 블록 단위 샘플링, FALSE이면 행 단위 샘플링.       |
| `method_opt`       | VARCHAR2    | 히스토그램 생성 옵션 (예: `'FOR ALL COLUMNS SIZE AUTO'`).                    |
| `degree`           | NUMBER      | 병렬 처리 degree. NULL이면 자동 결정.                                        |
| `granularity`      | VARCHAR2    | 통계 수집 granular level (예: `'ALL'`, `'AUTO'`, `'GLOBAL'`, `'PARTITION'`). |
| `cascade`          | BOOLEAN     | 인덱스 통계도 함께 수집할지 여부. TRUE이면 함께 수집.                        |
| `no_invalidate`    | BOOLEAN     | 기존 커서의 invalidation 여부. TRUE이면 즉시 invalidation 하지 않음.         |
| `stattab`          | VARCHAR2    | 통계 정보를 저장할 통계 테이블 이름 (백업용).                                |
| `statid`           | VARCHAR2    | `stattab`에 저장 시 식별용 ID.                                               |
| `statown`          | VARCHAR2    | `stattab`가 속한 스키마 이름.                                                |

## 컬럼 히스토그램 수집

히스토그램을 가지면 더 나은 실행계획을 수립하는 데 도움이 되지만 이를 수집하고 관리하는 비용이 만만치 않다.

따라서 필요한 컬럼에만 히스토그램을 수집해야 하며, 조건절에 자주 사용되면서 편중된 데이터 분포를 갖는 컬럼이 주 대상이다.

인덱스 컬럼에만 히스토그램이 필요하다고 생각하기 쉬운데 그렇지 않다.

테이블을 액세스하고 나서의 최종 선택도를 계산할 때는 인덱스가 없는 조건절 컬럼의 선택도도 인자로 사용되고,

그렇게 구해진 선택도에 따라 다른 집합과의 조인 순서 및 조인 방식이 결정되기 때문에 히스토그램이 필요하다.

아래와 같은 컬럼에는 히스토그램이 불필요하다.

-   컬럼 데이터 분포가 균일
-   Unique하고 항상 등치조건으로만 검색되는 컬럼
-   항상 바인드 변수로 검색되는 컬럼

dbms_stats.gather_table_stats에서 컬럼 히스토그램 수집과 관련된 인자는 method_opt다

10g 부터 기본값이 for all column size auto 로 바뀌었고 이는 오라클이 모든 컬럼에 대해 skew여부를 조사해서 버킷 개수를 결정하라는 뜻이다.

> Skew (스큐)란?
> 데이터 값들이 특정 값에 편중되어 있는 상태를 뜻합니다

이를 위해 오라클은 sys.col_usage$뷰를 참조한다.

오라클을 업그레이드 하면서 기본 동작 방식이 바뀐 사실을 모른채 낭패를 보는 경우가 종종 발생하므로 주의

없던 히스토그램이 생기면서 주요 SQL의 실행계획이 오히려 나쁜 쪽으로 바뀌는 예도 있거니와 통계정보 수집시간이 늘어나느 문제도 간과할 수 없다.

특히 큰 테이블일수록 디스크 소트 부하 때문에 시간이 오래 걸린다.

통계수집에 걸리는 시간이 짧은 테이블은 기본 값으로 둬도 상관없지만, 대용량 테이블일 때는 관리자가 직접 히스토그램 수집 컬럼을 아래와 같이 지정해 주는 것이 바람직하다.

> method_opt => 'for column coll size 20 col2 size 254 col3 size 100'

## 데이터 샘플링

샘플링 비율을 높일수록 통계정보의 정확도는 높아지지만 수집하는 데 더 많은 시간이 소요된다.

### 샘플링 비율

dbms-stats 패키지에서 샘플링 비율을 조정하기 위해 estimate_percent 인자를 사용한다.

이값을 무작정 크게 한다고 정확도가 선형적으로 증가하는 것은 아니며, 일정 비율 이상이면 대게 충분한 신뢰수준에 도달한다.

5%(대게 이정도면 충분)에서 시작해 값을 늘려가며 두세번만 통계를 수집해 보면 적정 크기를 결정할 수 있다.

### 블록 단위 샘플링

block_sample 인자를 통해 블록 단위 샘플링을 할지 로우 단위 샘플링을 할지 결정한다.

블록 단위 샘플링이 더 빠르고 효율적이긴 하지만, 데이터 분포가 고르지 않을때 정확도가 많이 떨어진다.

기본값은 로우 단위 샘플링이다.

### 안정적인 통계정보의 필요성

전수 검사할때는 그런일이 없겠지만 샘플링 방식을 사용하면 매번 통계치가 다르게 구해질 수 있고 이는 실행계획에 영향을 미쳐 SQL 성능을 불안정하게 만든다.

특히 컬럼에 NUll 값이 많거나 데이터 분포가 고르지 않을 때 그렇다.

선택도 구하는 공식의 세가지 구성요소가 Null 값을 제외한 로우 수 , Distinct Value 개수, 총 레코드 개수인 것을 상기하기 바란다.

특히 총 레코드 개수에 비해 나머지 두 통계치는 컬럼 분포가 고르지 않을 때 샘플링 비율에 의해 영향을 크게 받는다.

### 해시 기반 알고리즘으로 NDV 계산 - 11g

컬럼 히스토그램을 사용할 수 없을 때는 NDV(the number of distinct values)를 가지고 선택도를 계산하므로 이 값의 정확도가 매우 중요하다.

오라클 11g는 해시 기반의 새로운 알고리즘을 고안해 냈고, 대용량 파티션 또는 테이블 전체를 스캔하더라도 기존의 샘플링 방식을 사용할 때보다 오히려 빠른 속도를 낼 수 있게 되었다.

소트를 수행하지 않기 때문이며, 전체를 대상으로 NDV를 구하므로 정확도는 매우 높다. 빠르고 정확하면서도 안정적인 통계정보를 구현할 수 있게 된것

## 파티션 테이블 통계 수집

파티션 테이블일때 오라클은 테이블 레벨 통계(global 통계라고 함)와 파티션 레벨 통계를 따로 관리한다.

-   파티션 레벨 통계 : Static Partition Pruning이 작동할 때 사용된다. 결합 파티션일때는 서브파티션 레벨로 통계를 관리할 수 있다.

-   테이블 레벨 통계 : Dynamic Partition Pruning이 작동할 때 사용된다. 쿼리에 바인드 변수가 사용됐거나, 파티션 테이블이 NL조인에서 inner 쪽 테이블이면 액세스해야할 대상 파티션 목록을 쿼리 최적화 시점에 정할 수 없기 때문이다. (파티션 키에 대한 조건절이 없을때도 테이블 레벨 통계가 사용)

파티션 테이블 통계정보를 구할때는 더더욱 analyze보다 dbms_stats를 사용해야 한다.

dbms_stats은 global 통계를 위한 쿼리를 별도로 수행하는 반면, analyze는 파티션 통계를 가지고 global 통계를 유추하므로 부정확하다.

dbms_stats 패키지를 이용해 파티션 테이블의 통계를 수집할 때는 granularity 옵션을 신중하게 잘 선택해 줘야 하며, 아래와 같은 값들이 선택 가능하다.

-   global : 테이블 레벨 통계 수집
-   partition : 파티션 레벨 통계 수집
-   subpartition : 서브 파티션 레벨 통계 수집
-   global and partition : 테이블과 파티션 레벨 통계 수집
-   all : 테이블, 파티션, 서브 파티션 레벨 통계 수집
-   auto : 파티션 유형에 따라 오라클이 결정

테이블 통계와 파티션 통계를 같이 수집하려면 'global and partition'을 선택하면 된다.

내부적으로 global 통계를 위한 쿼리를 한 번 더 수행하므로 각각 수집할 때와 비교해 속도 차이는 없다.

## 인덱스 통계 수집

테이블 통계를 수집하면서 cascade 옵션을 true로 설정하면 테이블에 속한 모든 인덱스 통계도 같이 수집된다.

통계를 같이 수집한다고 해서 더 빠른 것은 아니며, 인덱스마다 gather_index_stats 프로시저를 따로 수행하는 것과 일량은 같다.

문제는 대용량 테이블이어서 샘플링 비율을 지정하면 인덱스 통계까지도 같은 비율이 적용된다는 데 있다.

인덱스는 통계수집에 걸리는 시간이 매우 짧아 굳이 샘플링 방식이 필요없는데도 말이다. (인덱스는 소트연산 불필요하기 때문에 빠름)

아래와 같이 테이블 통게만 샘플링 방식을 사용하고, 인덱스는 전수 검사하도록 각기 통계를 수집해 주는 것이 좋다.

```
begin
 -- 테이블 통계는 estimate mode
 dbms_stats.gather_table_stats( user, 'big_table', cascade => false, estimate_percent => 10);

 -- 인덱스 통계는 compute mode
 dbms_stats.gather_index_stats( user, 'big_table_pk', estimate_percent => 100);
 dbms_stats.gather_index_stats( user, 'big_table_xl', estimate_percent => 100);
end;
```

10g부터는 인덱스를 처음 생성하거나 재생성할 떄 인덱스 통계가 자동 수집되며, \_optimizer_compute_index_stats 파라미터를 통해 설정을 변경할 수 있다(기본값 true)

## 캐싱된 커서 Invalidation

no_invalidate 옵션을 어떻게 지정하느냐에 따라 통계를 수집한 테이블과 관련된 SQL 커서의 무효화 시점이 달라진다.

-   false : 통계정보 변경 시 관련된 SQL 커서들이 즉시 무효화된다. 따라서 곧이어 첫 번째 수행하는 세션에 의해, 새로 갱신된 통계정보를 이용해 실행 계획이 로드(하드파싱)된다.

-   true : 통계정보 변경 시 관련된 SQL 커서들을 무효화하지 않는다. SQL 커서가 자동으로 SharedPool에서 밀려났다가 다시 로드될 때 비로소 새로 갱신된 통계정보를 사용한다.

-   dbms_stats.auto_invalidate : 통계정보 변경 시 관련된 SQL 커서들을 한꺼번에 무효화하지 않고 정해진 시간동안 조금씩 무효화한다. 무효화된 수많은 커서가 동시에 수행되면서 하드 파싱에 의한 라이브러리 캐시 경합이 발생하는 현상을 방지하려고 10g에서 도입된 기능 (기본값)

## 자동 통계 수집

오라클 10g부터 기본적으로 매일 밤 10시부터 다음날 아침 6시까지 모든 사용자 오브젝트에 대한 통계를 자동 수집하도록 Job이 등록돼있다.

이 기능은 gather_stats_job에 의해 자동 수행되며, 통계정보가 없거나 통계정보 수집 후 DML이 많이 발생한 모든 오브젝트를 대상으로 한다.

### GATHER_STATS_JOB

gather_stats_job은 데이터베이스 생성 시 자동으로 등록되며, Maintenance 윈도우 그룹에 등록된 윈도우가 열릴 때마다 스케줄러에 의해 수행된다.

Maintenance 윈도우 그룹에는 아래 두 개 윈도우가 등록돼있다.

-   weeknight_window : 월요일부터 금요일까지 5일 동안, 매일 밤 10시부터 다음 날 아침 6시까지 8시간 동안 열림

-   weekend_window : 토요일 새벽 0시부터 2일동안 열림

자동 통계 수집 기능을 사용하지 않으려면 스케줄러 Job을 제거하면 된다.

### 통계정보 갱신 대상 식별

오라클은 통계정보 수집이 필요한 오브젝트인지를 판별하기 위해 테이블 모니터링 기능을 제공한다.

-   9i : nomonitoring 옵션을 기본이었고 필요한 테이블에만 관리자가 아래와 같이 옵션을 지정했지만 10g에서는 이 옵션이 아예 deprecated돼 모든 사용자 테이블이 모니터링 되고 있다.

statistics_level이 typical 또는 all일때 오라클은 monitoring 옵션이 지정된 테이블에 발생하는 DML 발생량을 모니터링 한다.

수집된 테이블별 DML 발생량은 \*\_tab_modifications뷰를 통해 조회해 볼 수 있으며, insert, updates, deletes 컬럼에 표시된 수치는 마지막 통계정보가 수집된 이후의 DML 발생량이다.

오라클은 모니터링 대상 테이블에 10%이상 변경이 발생했을 때 해당 테이블을 stale 상태로 바꾼다.

그리고나서 gather_database_stats또는 gather_schema_stats프로시저를 호출하면서 option인자에 gather stale 또는 gather auto를 지정하면

stale 상태인 테이블들에 대해 통계정보를 새로 수집한다.

11g에서는 stale 상태로 바뀌는 임게치를 오브젝트 별로 조정할 수 있다.

`실제로는 바로 변경하지 않고 모니터링 결과는 shared pool에 모았다가 smon이 주기적으로 (대략 3시간) 데이터 딕셔너리에 반영한다.`

현재까지의 변경사항이 딕셔너리에 바로 반영되도록 하려면 dbms_stats.flush_database_monitoring_info 프로시저를 호출하면 된다.

## 자동 통계 수집 기능 활용 가이드

관심을 두지 않고 방치한다면 오라클이 제공하는 자동 수집 기능에라도 의존하는 것이 나을 수 있다.

하지만 중대형급 이상 데이터베이스를 관리한다면 10g에서는 오브젝트별 전략을 세우고 가장 짧은 시간내에 정확하고 안정적인 통계정보를 수집할 수 있도록 별도의 스크립트를 준비하는 것이 좋다.

11g에서는 Statistics Preference 기능 때문에 자동 통계 수집 기능이 꽤 쓸만해졌다. 그렇더라도 오브젝트별 수집 전략을 여전히 필요하다.

## Statistics Preference

오브젝트 별로 일일이 스크립트를 작성하는 게 귀찮아 자동 통계 수집 기능을 그대로 사용하고 싶다면, 기본 설정을 적용하고 싶지 않은 오브젝트에만 lock을 설정한 상태에서 전체 통계를 수집하는 방법을 생각해 볼 수 있다.

전체 통계 수집이 끝나면 lock을 설정했던 오브젝트에 lock을 풀고 통계를 수집하는 별도의 job을 수행하면 된다.

이런 불편함을 위해 11g에서 Statistics Preference 라고 불리는 기능으로

gather_stats_job을 그대로 활성화한 상태에서 테이블 또는 스키마별로 통계 수집방식을 따로 설정할 수 있게 한것

그러면 자동 통계 수집기능이 작동할 때 해당 테이블 또는 스키마에 대해서는 기본 설정 값을 무시하고 사용자 지시사항에 따라 통계정보를 수집한다.

```sql
-- 아래와 같이 한 번만 설정
begin
  dbms_stats.set_table_prefs('ods', 'order', 'method_opt', 'for all indexed columns size auto');
  dbms_stats.set_table_prefs('ods', 'order', 'estimate_percent', 'dbms_stats.auto_sample_size');
  dbms_stats.set_table_prefs('ods', 'order', 'granularity', 'auto');
  ...
end;

-- Schema 레벨에서 통계정보 수집
exec dbms_stats.gather_schema_stats('ods');
```
